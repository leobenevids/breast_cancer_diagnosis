{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "previsores = pd.read_csv('entradas_breast.csv')\n",
    "classe = pd.read_csv('saidas_breast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede():\n",
    "    classificador = Sequential()\n",
    "\n",
    "    classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer='random_uniform', input_dim = 30))\n",
    "    classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer='random_uniform'))\n",
    "    classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer='random_uniform'))\n",
    "    classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer='random_uniform'))\n",
    "    classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer='random_uniform'))\n",
    "    \n",
    "    classificador.add(Dropout(0.2))\n",
    "    classificador.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    otimizador = tf.keras.optimizers.Adam(lr = 0.001, beta_1 = 0.0001, clipvalue = 0.5) \n",
    "    classificador.compile(optimizer = otimizador, loss = 'binary_crossentropy',\n",
    "                        metrics = ['binary_accuracy'])\n",
    "\n",
    "    return classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\951549~1\\AppData\\Local\\Temp/ipykernel_18136/2137071610.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  classificador = KerasClassifier(build_fn = criarRede, epochs=100, batch_size=10)\n"
     ]
    }
   ],
   "source": [
    "classificador = KerasClassifier(build_fn = criarRede, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 852us/step - loss: 0.6377 - binary_accuracy: 0.6855\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 800us/step - loss: 0.5148 - binary_accuracy: 0.7480\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4737 - binary_accuracy: 0.7793\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4070 - binary_accuracy: 0.8379\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 883us/step - loss: 0.3856 - binary_accuracy: 0.8340\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 970us/step - loss: 0.3734 - binary_accuracy: 0.8438\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 921us/step - loss: 0.3633 - binary_accuracy: 0.8477\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 960us/step - loss: 0.3192 - binary_accuracy: 0.8750\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 897us/step - loss: 0.3336 - binary_accuracy: 0.8613\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 820us/step - loss: 0.3007 - binary_accuracy: 0.8848\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 859us/step - loss: 0.3244 - binary_accuracy: 0.8750\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 909us/step - loss: 0.2672 - binary_accuracy: 0.8926\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.2803 - binary_accuracy: 0.8887\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 841us/step - loss: 0.3008 - binary_accuracy: 0.8730\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 811us/step - loss: 0.2731 - binary_accuracy: 0.8887\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 833us/step - loss: 0.2738 - binary_accuracy: 0.9004\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 868us/step - loss: 0.2519 - binary_accuracy: 0.9043\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 932us/step - loss: 0.2752 - binary_accuracy: 0.9004\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 864us/step - loss: 0.2620 - binary_accuracy: 0.9062\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 801us/step - loss: 0.2449 - binary_accuracy: 0.9102\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 848us/step - loss: 0.2515 - binary_accuracy: 0.9043\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 858us/step - loss: 0.2332 - binary_accuracy: 0.9160\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 808us/step - loss: 0.2392 - binary_accuracy: 0.9062\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 879us/step - loss: 0.2281 - binary_accuracy: 0.9141\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 765us/step - loss: 0.2415 - binary_accuracy: 0.9004\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 819us/step - loss: 0.3030 - binary_accuracy: 0.8887\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 840us/step - loss: 0.2802 - binary_accuracy: 0.9102\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2749 - binary_accuracy: 0.9082\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 899us/step - loss: 0.2820 - binary_accuracy: 0.9062\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 868us/step - loss: 0.2576 - binary_accuracy: 0.9277\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 763us/step - loss: 0.2297 - binary_accuracy: 0.9199\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 891us/step - loss: 0.2116 - binary_accuracy: 0.9141\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.2114 - binary_accuracy: 0.9336\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 802us/step - loss: 0.2122 - binary_accuracy: 0.9160\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 832us/step - loss: 0.2464 - binary_accuracy: 0.9043\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 821us/step - loss: 0.2078 - binary_accuracy: 0.9219\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.2045 - binary_accuracy: 0.9238\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 823us/step - loss: 0.2171 - binary_accuracy: 0.9180\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 821us/step - loss: 0.2080 - binary_accuracy: 0.9180\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 851us/step - loss: 0.2139 - binary_accuracy: 0.9219\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 918us/step - loss: 0.2036 - binary_accuracy: 0.9336\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 802us/step - loss: 0.1974 - binary_accuracy: 0.9355\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 783us/step - loss: 0.1933 - binary_accuracy: 0.9297\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 840us/step - loss: 0.2932 - binary_accuracy: 0.9121\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 823us/step - loss: 0.2343 - binary_accuracy: 0.9141\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.1839 - binary_accuracy: 0.9297\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 845us/step - loss: 0.1894 - binary_accuracy: 0.9316\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 774us/step - loss: 0.1939 - binary_accuracy: 0.9297\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 841us/step - loss: 0.2379 - binary_accuracy: 0.9199\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 907us/step - loss: 0.1782 - binary_accuracy: 0.9316\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 807us/step - loss: 0.1699 - binary_accuracy: 0.9277\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.1678 - binary_accuracy: 0.9297\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 819us/step - loss: 0.1974 - binary_accuracy: 0.9277\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 915us/step - loss: 0.1987 - binary_accuracy: 0.9277\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.8435 - binary_accuracy: 0.700 - 0s 958us/step - loss: 0.2015 - binary_accuracy: 0.9355\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 878us/step - loss: 0.1778 - binary_accuracy: 0.9316\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 805us/step - loss: 0.1914 - binary_accuracy: 0.9414\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 783us/step - loss: 0.1928 - binary_accuracy: 0.9297\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 848us/step - loss: 0.1530 - binary_accuracy: 0.9395\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 743us/step - loss: 0.1660 - binary_accuracy: 0.9414\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 808us/step - loss: 0.1897 - binary_accuracy: 0.9219\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 820us/step - loss: 0.1732 - binary_accuracy: 0.9238\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 799us/step - loss: 0.1508 - binary_accuracy: 0.9473\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 879us/step - loss: 0.1797 - binary_accuracy: 0.9277\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 861us/step - loss: 0.1714 - binary_accuracy: 0.9355\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 743us/step - loss: 0.1697 - binary_accuracy: 0.9355\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 821us/step - loss: 0.1625 - binary_accuracy: 0.9453\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 804us/step - loss: 0.1399 - binary_accuracy: 0.9492\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 793us/step - loss: 0.1714 - binary_accuracy: 0.9355\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 792us/step - loss: 0.2272 - binary_accuracy: 0.9434\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 846us/step - loss: 0.1705 - binary_accuracy: 0.9336\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 800us/step - loss: 0.2901 - binary_accuracy: 0.9316\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 903us/step - loss: 0.1816 - binary_accuracy: 0.9316\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 821us/step - loss: 0.1582 - binary_accuracy: 0.9355\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 762us/step - loss: 0.1614 - binary_accuracy: 0.9316\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 802us/step - loss: 0.1630 - binary_accuracy: 0.9375\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 868us/step - loss: 0.1545 - binary_accuracy: 0.9336\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 784us/step - loss: 0.3470 - binary_accuracy: 0.9277\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 798us/step - loss: 0.1747 - binary_accuracy: 0.9355\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 832us/step - loss: 0.2732 - binary_accuracy: 0.9297\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 802us/step - loss: 0.1825 - binary_accuracy: 0.9375\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 802us/step - loss: 0.2593 - binary_accuracy: 0.9355\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 820us/step - loss: 0.1515 - binary_accuracy: 0.9414\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 810us/step - loss: 0.1696 - binary_accuracy: 0.9238\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 864us/step - loss: 0.1815 - binary_accuracy: 0.9238\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 899us/step - loss: 0.1487 - binary_accuracy: 0.9434\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1622 - binary_accuracy: 0.9375\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1594 - binary_accuracy: 0.9434\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 938us/step - loss: 0.1561 - binary_accuracy: 0.9453\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0330 - binary_accuracy: 1.000 - 0s 861us/step - loss: 0.1831 - binary_accuracy: 0.9277\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.1814 - binary_accuracy: 0.9219\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 841us/step - loss: 0.1598 - binary_accuracy: 0.9375\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.1786 - binary_accuracy: 0.9297\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.1850 - binary_accuracy: 0.9355\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2183 - binary_accuracy: 0.9238\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.1758 - binary_accuracy: 0.9355\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.1837 - binary_accuracy: 0.9258\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.1952 - binary_accuracy: 0.9297\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.1596 - binary_accuracy: 0.9375\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1735 - binary_accuracy: 0.9297\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 939us/step - loss: 0.6597 - binary_accuracy: 0.6406\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.5367 - binary_accuracy: 0.6738\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.4865 - binary_accuracy: 0.7129\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.4548 - binary_accuracy: 0.8086\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.4231 - binary_accuracy: 0.8301\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.4101 - binary_accuracy: 0.8496\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3549 - binary_accuracy: 0.8535\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.3470 - binary_accuracy: 0.8633\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.3382 - binary_accuracy: 0.8633\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.3297 - binary_accuracy: 0.8633\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.3463 - binary_accuracy: 0.8730\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 984us/step - loss: 0.3188 - binary_accuracy: 0.8750\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 944us/step - loss: 0.2971 - binary_accuracy: 0.8750\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 808us/step - loss: 0.3283 - binary_accuracy: 0.8652\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 821us/step - loss: 0.2985 - binary_accuracy: 0.8887\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 836us/step - loss: 0.2765 - binary_accuracy: 0.9023\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 834us/step - loss: 0.2866 - binary_accuracy: 0.8926\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.2805 - binary_accuracy: 0.9043\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 814us/step - loss: 0.2819 - binary_accuracy: 0.8887\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 763us/step - loss: 0.2799 - binary_accuracy: 0.8906\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 801us/step - loss: 0.2556 - binary_accuracy: 0.9160\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 782us/step - loss: 0.2554 - binary_accuracy: 0.9102\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 761us/step - loss: 0.2377 - binary_accuracy: 0.9043\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 838us/step - loss: 0.2489 - binary_accuracy: 0.9238\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 910us/step - loss: 0.2678 - binary_accuracy: 0.8789\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 850us/step - loss: 0.2539 - binary_accuracy: 0.8984\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2485 - binary_accuracy: 0.9043\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.2440 - binary_accuracy: 0.9102\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 782us/step - loss: 0.2283 - binary_accuracy: 0.9043\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 801us/step - loss: 0.2226 - binary_accuracy: 0.9160\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 834us/step - loss: 0.2322 - binary_accuracy: 0.9082\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 754us/step - loss: 0.2257 - binary_accuracy: 0.9141\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2257 - binary_accuracy: 0.9141\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2500 - binary_accuracy: 0.9043\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2246 - binary_accuracy: 0.9258\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.2697 - binary_accuracy: 0.9199\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 893us/step - loss: 0.2561 - binary_accuracy: 0.9004\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2632 - binary_accuracy: 0.9004\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2149 - binary_accuracy: 0.9180\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2056 - binary_accuracy: 0.9141\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2137 - binary_accuracy: 0.9121\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2809 - binary_accuracy: 0.9219\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2027 - binary_accuracy: 0.9219\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2117 - binary_accuracy: 0.9238\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 911us/step - loss: 0.2132 - binary_accuracy: 0.9062\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.2583 - binary_accuracy: 0.9180\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 918us/step - loss: 0.2088 - binary_accuracy: 0.9297\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.1987 - binary_accuracy: 0.9082\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 899us/step - loss: 0.2471 - binary_accuracy: 0.9336\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2284 - binary_accuracy: 0.9219\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2376 - binary_accuracy: 0.9297\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2523 - binary_accuracy: 0.9199\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2195 - binary_accuracy: 0.9180\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 975us/step - loss: 0.2114 - binary_accuracy: 0.9297\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.1862 - binary_accuracy: 0.9336\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2629 - binary_accuracy: 0.9258\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.1937 - binary_accuracy: 0.9238\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1863 - binary_accuracy: 0.9375\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 881us/step - loss: 0.2037 - binary_accuracy: 0.9043\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2613 - binary_accuracy: 0.800 - 0s 958us/step - loss: 0.2833 - binary_accuracy: 0.9336\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 938us/step - loss: 0.1819 - binary_accuracy: 0.9316\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2573 - binary_accuracy: 0.9414\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1900 - binary_accuracy: 0.9297\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2202 - binary_accuracy: 0.9238\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2126 - binary_accuracy: 0.9160\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1770 - binary_accuracy: 0.9297\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1710 - binary_accuracy: 0.9414\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1931 - binary_accuracy: 0.9297\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.1983 - binary_accuracy: 0.9238\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 896us/step - loss: 0.1670 - binary_accuracy: 0.9414\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1721 - binary_accuracy: 0.9336\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1704 - binary_accuracy: 0.9297\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1826 - binary_accuracy: 0.9355\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1827 - binary_accuracy: 0.9141\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2556 - binary_accuracy: 0.9238\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 936us/step - loss: 0.1722 - binary_accuracy: 0.9297\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1640 - binary_accuracy: 0.9395\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2399 - binary_accuracy: 0.9336\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1710 - binary_accuracy: 0.9297\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1537 - binary_accuracy: 0.9375\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1698 - binary_accuracy: 0.9258\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1619 - binary_accuracy: 0.9395\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 947us/step - loss: 0.1640 - binary_accuracy: 0.9336\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1876 - binary_accuracy: 0.9238\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2031 - binary_accuracy: 0.9141\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 937us/step - loss: 0.1931 - binary_accuracy: 0.9277\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 973us/step - loss: 0.2163 - binary_accuracy: 0.9297\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 871us/step - loss: 0.1957 - binary_accuracy: 0.9199\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2009 - binary_accuracy: 0.9121\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1722 - binary_accuracy: 0.9336\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1582 - binary_accuracy: 0.9395\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1651 - binary_accuracy: 0.9258\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1610 - binary_accuracy: 0.9414\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 993us/step - loss: 0.1766 - binary_accuracy: 0.9355\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.1733 - binary_accuracy: 0.9355\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.1765 - binary_accuracy: 0.9336\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2284 - binary_accuracy: 0.9277\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2629 - binary_accuracy: 0.9219\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.1605 - binary_accuracy: 0.9395\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 898us/step - loss: 0.1761 - binary_accuracy: 0.9395\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6259 - binary_accuracy: 0.6250\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5689 - binary_accuracy: 0.6641\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5153 - binary_accuracy: 0.7598\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4839 - binary_accuracy: 0.7363\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.4452 - binary_accuracy: 0.807 - 0s 1ms/step - loss: 0.4503 - binary_accuracy: 0.8066\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4198 - binary_accuracy: 0.8418\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3983 - binary_accuracy: 0.8496\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3662 - binary_accuracy: 0.8613\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3366 - binary_accuracy: 0.8789\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3418 - binary_accuracy: 0.8691\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3124 - binary_accuracy: 0.8730\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3073 - binary_accuracy: 0.8770\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3488 - binary_accuracy: 0.8750\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 976us/step - loss: 0.3030 - binary_accuracy: 0.8750\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2825 - binary_accuracy: 0.8887\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3011 - binary_accuracy: 0.8965\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2752 - binary_accuracy: 0.8926\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3149 - binary_accuracy: 0.8750\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.3258 - binary_accuracy: 0.8691\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.3338 - binary_accuracy: 0.8848\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.2845 - binary_accuracy: 0.8828\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2692 - binary_accuracy: 0.9102\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2615 - binary_accuracy: 0.9004\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2602 - binary_accuracy: 0.9043\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.2717 - binary_accuracy: 0.8828\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2387 - binary_accuracy: 0.9062\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2644 - binary_accuracy: 0.9102\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2742 - binary_accuracy: 0.8945\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2803 - binary_accuracy: 0.8828\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 861us/step - loss: 0.2836 - binary_accuracy: 0.9043\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2374 - binary_accuracy: 0.9160\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2547 - binary_accuracy: 0.9004\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 899us/step - loss: 0.2836 - binary_accuracy: 0.9199\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2306 - binary_accuracy: 0.9121\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2347 - binary_accuracy: 0.8965\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2312 - binary_accuracy: 0.9160\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2313 - binary_accuracy: 0.9082\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3227 - binary_accuracy: 0.9121\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2430 - binary_accuracy: 0.9004\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2844 - binary_accuracy: 0.9219\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.2794 - binary_accuracy: 0.9180\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2202 - binary_accuracy: 0.9062\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2040 - binary_accuracy: 0.9121\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2366 - binary_accuracy: 0.9180\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.2318 - binary_accuracy: 0.9082\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2363 - binary_accuracy: 0.8906\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2103 - binary_accuracy: 0.9219\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 821us/step - loss: 0.1896 - binary_accuracy: 0.9219\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 935us/step - loss: 0.2498 - binary_accuracy: 0.9102\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2170 - binary_accuracy: 0.9180\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 927us/step - loss: 0.1977 - binary_accuracy: 0.9277\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 969us/step - loss: 0.2023 - binary_accuracy: 0.9238\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.3137 - binary_accuracy: 0.9082\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.1980 - binary_accuracy: 0.9199\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2247 - binary_accuracy: 0.9102\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2977 - binary_accuracy: 0.9180\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2017 - binary_accuracy: 0.9180\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2066 - binary_accuracy: 0.9160\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.2592 - binary_accuracy: 0.9102\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2183 - binary_accuracy: 0.9023\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2253 - binary_accuracy: 0.9258\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2286 - binary_accuracy: 0.9043\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.3566 - binary_accuracy: 0.9043\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.1925 - binary_accuracy: 0.9258\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2880 - binary_accuracy: 0.9219\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1889 - binary_accuracy: 0.9180\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1822 - binary_accuracy: 0.9277\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.3316 - binary_accuracy: 0.9277\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 993us/step - loss: 0.2280 - binary_accuracy: 0.9062\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2179 - binary_accuracy: 0.9082\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3361 - binary_accuracy: 0.9121\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2032 - binary_accuracy: 0.9199\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2051 - binary_accuracy: 0.9141\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1929 - binary_accuracy: 0.9258\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2162 - binary_accuracy: 0.9023\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1752 - binary_accuracy: 0.9258\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2197 - binary_accuracy: 0.9199\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2120 - binary_accuracy: 0.9180\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1956 - binary_accuracy: 0.9238\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1980 - binary_accuracy: 0.9160\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.1853 - binary_accuracy: 0.9199\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.2167 - binary_accuracy: 0.9062\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 993us/step - loss: 0.1988 - binary_accuracy: 0.9316\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2140 - binary_accuracy: 0.9102\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.2111 - binary_accuracy: 0.9004\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 974us/step - loss: 0.1852 - binary_accuracy: 0.9336\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 879us/step - loss: 0.1946 - binary_accuracy: 0.9238\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.2021 - binary_accuracy: 0.9238\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2237 - binary_accuracy: 0.9082\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.2029 - binary_accuracy: 0.9238\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.1890 - binary_accuracy: 0.9199\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2042 - binary_accuracy: 0.9180\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2003 - binary_accuracy: 0.9180A: 0s - loss: 0.2008 - binary_accuracy: 0.917\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2033 - binary_accuracy: 0.9238\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1759 - binary_accuracy: 0.9316\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 977us/step - loss: 0.2089 - binary_accuracy: 0.9219\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1853 - binary_accuracy: 0.9160\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.1809 - binary_accuracy: 0.9219\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1999 - binary_accuracy: 0.9180\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.1921 - binary_accuracy: 0.9238\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 1ms/step - loss: 0.6231 - binary_accuracy: 0.6797\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.5042 - binary_accuracy: 0.6777\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4870 - binary_accuracy: 0.7148\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4668 - binary_accuracy: 0.7656\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4375 - binary_accuracy: 0.8359A: 0s - loss: 0.4511 - binary_accuracy: 0.827\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3997 - binary_accuracy: 0.8477\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3734 - binary_accuracy: 0.8574\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3609 - binary_accuracy: 0.8652\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3388 - binary_accuracy: 0.8691\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1302 - binary_accuracy: 1.000 - 0s 981us/step - loss: 0.3207 - binary_accuracy: 0.8906\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3078 - binary_accuracy: 0.8711\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2839 - binary_accuracy: 0.9102\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3004 - binary_accuracy: 0.8691\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2660 - binary_accuracy: 0.8945\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2499 - binary_accuracy: 0.9121\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2653 - binary_accuracy: 0.8789\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2488 - binary_accuracy: 0.9082\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 970us/step - loss: 0.2258 - binary_accuracy: 0.9062\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 963us/step - loss: 0.2361 - binary_accuracy: 0.9160\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 942us/step - loss: 0.2301 - binary_accuracy: 0.9160\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2264 - binary_accuracy: 0.9219\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2190 - binary_accuracy: 0.9160\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2165 - binary_accuracy: 0.9199\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2496 - binary_accuracy: 0.9062\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2130 - binary_accuracy: 0.9199\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2190 - binary_accuracy: 0.9219A: 0s - loss: 0.2218 - binary_accuracy: 0.920\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2199 - binary_accuracy: 0.9160\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.1941 - binary_accuracy: 0.9258\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 879us/step - loss: 0.2254 - binary_accuracy: 0.9199\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2257 - binary_accuracy: 0.9180\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2101 - binary_accuracy: 0.9219\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2080 - binary_accuracy: 0.919 - 0s 1ms/step - loss: 0.1973 - binary_accuracy: 0.9258\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1969 - binary_accuracy: 0.9355\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2049 - binary_accuracy: 0.9277\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.1880 - binary_accuracy: 0.9414\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1980 - binary_accuracy: 0.9238\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 946us/step - loss: 0.1925 - binary_accuracy: 0.9277\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.1989 - binary_accuracy: 0.9199\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1932 - binary_accuracy: 0.9316\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1788 - binary_accuracy: 0.9258\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 829us/step - loss: 0.2101 - binary_accuracy: 0.9238\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 965us/step - loss: 0.1876 - binary_accuracy: 0.9316\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1831 - binary_accuracy: 0.9316\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 758us/step - loss: 0.1654 - binary_accuracy: 0.9316\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.1879 - binary_accuracy: 0.9277\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 923us/step - loss: 0.1812 - binary_accuracy: 0.9316\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 948us/step - loss: 0.1850 - binary_accuracy: 0.9297\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 940us/step - loss: 0.1597 - binary_accuracy: 0.9492\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1856 - binary_accuracy: 0.9297\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1768 - binary_accuracy: 0.9375\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.1552 - binary_accuracy: 0.9453\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1677 - binary_accuracy: 0.9453\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 954us/step - loss: 0.1824 - binary_accuracy: 0.9375\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 801us/step - loss: 0.2248 - binary_accuracy: 0.9336\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.1779 - binary_accuracy: 0.9395\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 884us/step - loss: 0.1786 - binary_accuracy: 0.9297\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.1906 - binary_accuracy: 0.9355\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1724 - binary_accuracy: 0.9355\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.1713 - binary_accuracy: 0.9219\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 896us/step - loss: 0.1637 - binary_accuracy: 0.9414\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 881us/step - loss: 0.1601 - binary_accuracy: 0.9434\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 840us/step - loss: 0.2226 - binary_accuracy: 0.9258\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1723 - binary_accuracy: 0.9355\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.1787 - binary_accuracy: 0.9316\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 971us/step - loss: 0.1722 - binary_accuracy: 0.9258\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1711 - binary_accuracy: 0.9375\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1804 - binary_accuracy: 0.9199\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 796us/step - loss: 0.1722 - binary_accuracy: 0.9316\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 857us/step - loss: 0.1730 - binary_accuracy: 0.9297\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.1792 - binary_accuracy: 0.9258\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 954us/step - loss: 0.1742 - binary_accuracy: 0.9375\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1685 - binary_accuracy: 0.9473\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1777 - binary_accuracy: 0.9297\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1739 - binary_accuracy: 0.9316\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 877us/step - loss: 0.1553 - binary_accuracy: 0.9414\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 878us/step - loss: 0.1720 - binary_accuracy: 0.9355\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1797 - binary_accuracy: 0.9297\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1560 - binary_accuracy: 0.9473\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1851 - binary_accuracy: 0.9355\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1535 - binary_accuracy: 0.9414\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1749 - binary_accuracy: 0.9414\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1832 - binary_accuracy: 0.9395\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1652 - binary_accuracy: 0.9414\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1737 - binary_accuracy: 0.9316\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 925us/step - loss: 0.1658 - binary_accuracy: 0.9336\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2205 - binary_accuracy: 0.9180\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1551 - binary_accuracy: 0.9375\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1711 - binary_accuracy: 0.9297\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1735 - binary_accuracy: 0.9336\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.1502 - binary_accuracy: 0.9453\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 841us/step - loss: 0.1829 - binary_accuracy: 0.9297\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.1681 - binary_accuracy: 0.9355\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1883 - binary_accuracy: 0.9414\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1777 - binary_accuracy: 0.9395\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 937us/step - loss: 0.1807 - binary_accuracy: 0.9355\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.1666 - binary_accuracy: 0.9355\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.1664 - binary_accuracy: 0.9395\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1530 - binary_accuracy: 0.9492\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1512 - binary_accuracy: 0.9453\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1547 - binary_accuracy: 0.9434\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 943us/step - loss: 0.6371 - binary_accuracy: 0.6719\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5561 - binary_accuracy: 0.6934\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5198 - binary_accuracy: 0.7051\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4931 - binary_accuracy: 0.7402\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4844 - binary_accuracy: 0.7578\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4410 - binary_accuracy: 0.8340\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4311 - binary_accuracy: 0.8281\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3883 - binary_accuracy: 0.8438\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3607 - binary_accuracy: 0.8574\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3387 - binary_accuracy: 0.8555\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.3366 - binary_accuracy: 0.8574\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3124 - binary_accuracy: 0.8828\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2838 - binary_accuracy: 0.8887\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2857 - binary_accuracy: 0.8848\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.2803 - binary_accuracy: 0.8789\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2806 - binary_accuracy: 0.8691\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2405 - binary_accuracy: 0.9043\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2490 - binary_accuracy: 0.8984\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2443 - binary_accuracy: 0.9062\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 857us/step - loss: 0.2362 - binary_accuracy: 0.8965\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.2369 - binary_accuracy: 0.8965\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 934us/step - loss: 0.2287 - binary_accuracy: 0.9023\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.2522 - binary_accuracy: 0.8867\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 931us/step - loss: 0.2322 - binary_accuracy: 0.8965\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 940us/step - loss: 0.2610 - binary_accuracy: 0.8926\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 823us/step - loss: 0.2455 - binary_accuracy: 0.9023\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2308 - binary_accuracy: 0.9023\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2413 - binary_accuracy: 0.9180\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2871 - binary_accuracy: 0.8926\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2532 - binary_accuracy: 0.9023\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2128 - binary_accuracy: 0.9121\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2726 - binary_accuracy: 0.8945\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2431 - binary_accuracy: 0.8965\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2425 - binary_accuracy: 0.9023\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 851us/step - loss: 0.2051 - binary_accuracy: 0.9258\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 885us/step - loss: 0.2219 - binary_accuracy: 0.9102\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2288 - binary_accuracy: 0.9082\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.2846 - binary_accuracy: 0.8926\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2242 - binary_accuracy: 0.9043\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 949us/step - loss: 0.2045 - binary_accuracy: 0.9199\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2101 - binary_accuracy: 0.9141\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 912us/step - loss: 0.1954 - binary_accuracy: 0.9102\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1957 - binary_accuracy: 0.9258\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2230 - binary_accuracy: 0.9043\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2135 - binary_accuracy: 0.9141\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 995us/step - loss: 0.2190 - binary_accuracy: 0.9062\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 899us/step - loss: 0.2041 - binary_accuracy: 0.9238\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 743us/step - loss: 0.1958 - binary_accuracy: 0.9258\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2121 - binary_accuracy: 0.9121\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 953us/step - loss: 0.1914 - binary_accuracy: 0.9160\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 841us/step - loss: 0.2046 - binary_accuracy: 0.9102\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2078 - binary_accuracy: 0.9219\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 928us/step - loss: 0.2411 - binary_accuracy: 0.9199\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2067 - binary_accuracy: 0.9277\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.2483 - binary_accuracy: 0.9082\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.2328 - binary_accuracy: 0.9141\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 826us/step - loss: 0.2200 - binary_accuracy: 0.9082\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.3715 - binary_accuracy: 0.8867\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 964us/step - loss: 0.2086 - binary_accuracy: 0.9082\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.3258 - binary_accuracy: 0.9199\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.2041 - binary_accuracy: 0.9180\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1584 - binary_accuracy: 0.900 - 0s 959us/step - loss: 0.2089 - binary_accuracy: 0.9238\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 969us/step - loss: 0.2108 - binary_accuracy: 0.9180\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2101 - binary_accuracy: 0.9160\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 841us/step - loss: 0.2156 - binary_accuracy: 0.9199\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2097 - binary_accuracy: 0.9180\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1679 - binary_accuracy: 0.9336\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 893us/step - loss: 0.1950 - binary_accuracy: 0.9141\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 815us/step - loss: 0.1969 - binary_accuracy: 0.9297\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1890 - binary_accuracy: 0.9199\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1703 - binary_accuracy: 0.9336\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1856 - binary_accuracy: 0.9375\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.1918 - binary_accuracy: 0.9199\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.1724 - binary_accuracy: 0.9395\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.1951 - binary_accuracy: 0.9219\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1890 - binary_accuracy: 0.9102\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1852 - binary_accuracy: 0.9238\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1843 - binary_accuracy: 0.9277\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1831 - binary_accuracy: 0.9258\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1846 - binary_accuracy: 0.9375\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2048 - binary_accuracy: 0.9141\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.1840 - binary_accuracy: 0.9355\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1887 - binary_accuracy: 0.9395\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1846 - binary_accuracy: 0.9277\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1960 - binary_accuracy: 0.9062\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1771 - binary_accuracy: 0.9316\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1827 - binary_accuracy: 0.9238\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1723 - binary_accuracy: 0.9395\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1794 - binary_accuracy: 0.9277\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2010 - binary_accuracy: 0.9297\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 821us/step - loss: 0.1867 - binary_accuracy: 0.9258\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.1690 - binary_accuracy: 0.9336\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 988us/step - loss: 0.1729 - binary_accuracy: 0.9258\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 822us/step - loss: 0.1641 - binary_accuracy: 0.9355\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2653 - binary_accuracy: 0.800 - 0s 880us/step - loss: 0.1767 - binary_accuracy: 0.9219\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 915us/step - loss: 0.1720 - binary_accuracy: 0.9355\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.1727 - binary_accuracy: 0.9297\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.1650 - binary_accuracy: 0.9414\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1757 - binary_accuracy: 0.9355\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.1828 - binary_accuracy: 0.9316\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 962us/step - loss: 0.6125 - binary_accuracy: 0.6602\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 931us/step - loss: 0.5125 - binary_accuracy: 0.6758\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5023 - binary_accuracy: 0.7051\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4774 - binary_accuracy: 0.7715\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.4219 - binary_accuracy: 0.8262\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3808 - binary_accuracy: 0.8398\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3674 - binary_accuracy: 0.8516\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3350 - binary_accuracy: 0.8652\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3339 - binary_accuracy: 0.8516\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3176 - binary_accuracy: 0.8809\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 938us/step - loss: 0.3038 - binary_accuracy: 0.8789\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2948 - binary_accuracy: 0.8828\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.2888 - binary_accuracy: 0.8750\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.2952 - binary_accuracy: 0.8828\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2710 - binary_accuracy: 0.8867\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2834 - binary_accuracy: 0.8926\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2581 - binary_accuracy: 0.8887\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 861us/step - loss: 0.2553 - binary_accuracy: 0.8984\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.2688 - binary_accuracy: 0.9023\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 948us/step - loss: 0.2514 - binary_accuracy: 0.9062\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 842us/step - loss: 0.2492 - binary_accuracy: 0.8945\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2377 - binary_accuracy: 0.9023\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 889us/step - loss: 0.2568 - binary_accuracy: 0.9062\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 938us/step - loss: 0.2432 - binary_accuracy: 0.9082\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 841us/step - loss: 0.2288 - binary_accuracy: 0.9102\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 972us/step - loss: 0.2535 - binary_accuracy: 0.9043\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.2659 - binary_accuracy: 0.8906\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2814 - binary_accuracy: 0.9141\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.2680 - binary_accuracy: 0.8828\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2753 - binary_accuracy: 0.9141\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2247 - binary_accuracy: 0.9102\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 896us/step - loss: 0.2626 - binary_accuracy: 0.9121\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2122 - binary_accuracy: 0.9258\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 938us/step - loss: 0.2117 - binary_accuracy: 0.9219\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 918us/step - loss: 0.2246 - binary_accuracy: 0.9062\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 914us/step - loss: 0.2115 - binary_accuracy: 0.9062\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 956us/step - loss: 0.2104 - binary_accuracy: 0.9180\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.2359 - binary_accuracy: 0.9062\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 960us/step - loss: 0.2126 - binary_accuracy: 0.9062\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.1998 - binary_accuracy: 0.9238\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2150 - binary_accuracy: 0.9121\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2189 - binary_accuracy: 0.9160\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 879us/step - loss: 0.2167 - binary_accuracy: 0.9141\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 944us/step - loss: 0.2484 - binary_accuracy: 0.9004\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.2222 - binary_accuracy: 0.9219\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 852us/step - loss: 0.2238 - binary_accuracy: 0.9199\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 898us/step - loss: 0.2084 - binary_accuracy: 0.9121\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 923us/step - loss: 0.2010 - binary_accuracy: 0.9199\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 875us/step - loss: 0.2278 - binary_accuracy: 0.9199\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.1914 - binary_accuracy: 0.9316\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 836us/step - loss: 0.2124 - binary_accuracy: 0.9121\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 840us/step - loss: 0.2048 - binary_accuracy: 0.9160\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1949 - binary_accuracy: 0.9199\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 749us/step - loss: 0.1976 - binary_accuracy: 0.9375\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.1824 - binary_accuracy: 0.9219\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 857us/step - loss: 0.2026 - binary_accuracy: 0.9238\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2004 - binary_accuracy: 0.9277\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.2685 - binary_accuracy: 0.9219\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 861us/step - loss: 0.2765 - binary_accuracy: 0.9199\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1924 - binary_accuracy: 0.9316\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.1982 - binary_accuracy: 0.9219\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2068 - binary_accuracy: 0.9102\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 829us/step - loss: 0.2755 - binary_accuracy: 0.9082\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 954us/step - loss: 0.1965 - binary_accuracy: 0.9277\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 802us/step - loss: 0.2016 - binary_accuracy: 0.9121\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.1961 - binary_accuracy: 0.9219\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 920us/step - loss: 0.2092 - binary_accuracy: 0.9199\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 782us/step - loss: 0.1994 - binary_accuracy: 0.9219\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.2071 - binary_accuracy: 0.9141\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.3215 - binary_accuracy: 0.9238\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 892us/step - loss: 0.2307 - binary_accuracy: 0.9160\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.2031 - binary_accuracy: 0.9160\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 911us/step - loss: 0.2138 - binary_accuracy: 0.9199\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 837us/step - loss: 0.1973 - binary_accuracy: 0.9238\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 935us/step - loss: 0.2142 - binary_accuracy: 0.9277\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2622 - binary_accuracy: 0.800 - 0s 927us/step - loss: 0.2095 - binary_accuracy: 0.9219\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 841us/step - loss: 0.1896 - binary_accuracy: 0.9375\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1948 - binary_accuracy: 0.9180A: 0s - loss: 0.1948 - binary_accuracy: 0.918\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2055 - binary_accuracy: 0.9160\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1936 - binary_accuracy: 0.9355\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.2060 - binary_accuracy: 0.9316\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.2139 - binary_accuracy: 0.9180\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 969us/step - loss: 0.1937 - binary_accuracy: 0.9336\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 763us/step - loss: 0.1817 - binary_accuracy: 0.9336\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.4240 - binary_accuracy: 0.800 - 0s 939us/step - loss: 0.2988 - binary_accuracy: 0.9238\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 865us/step - loss: 0.2088 - binary_accuracy: 0.9355\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 918us/step - loss: 0.1885 - binary_accuracy: 0.9238\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.1788 - binary_accuracy: 0.9258\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 982us/step - loss: 0.1661 - binary_accuracy: 0.9375\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.2054 - binary_accuracy: 0.9180\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1035 - binary_accuracy: 1.000 - 0s 980us/step - loss: 0.1849 - binary_accuracy: 0.9180\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.1939 - binary_accuracy: 0.9160\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 926us/step - loss: 0.2184 - binary_accuracy: 0.9043\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 848us/step - loss: 0.1899 - binary_accuracy: 0.9258\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 864us/step - loss: 0.2022 - binary_accuracy: 0.9199\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1993 - binary_accuracy: 0.9238\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 938us/step - loss: 0.1941 - binary_accuracy: 0.9238\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 761us/step - loss: 0.1863 - binary_accuracy: 0.9336\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.1886 - binary_accuracy: 0.9277\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 953us/step - loss: 0.1913 - binary_accuracy: 0.9180\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 874us/step - loss: 0.6173 - binary_accuracy: 0.6465\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.5030 - binary_accuracy: 0.6797\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 963us/step - loss: 0.5035 - binary_accuracy: 0.6621\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4918 - binary_accuracy: 0.7266\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4574 - binary_accuracy: 0.7383\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4499 - binary_accuracy: 0.7891\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4294 - binary_accuracy: 0.8242\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4109 - binary_accuracy: 0.8438\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3962 - binary_accuracy: 0.8516\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.3646 - binary_accuracy: 0.860 - 0s 1ms/step - loss: 0.3562 - binary_accuracy: 0.8672\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3396 - binary_accuracy: 0.8848\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3232 - binary_accuracy: 0.8770\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3128 - binary_accuracy: 0.8984\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2903 - binary_accuracy: 0.9062\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3069 - binary_accuracy: 0.8906\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2873 - binary_accuracy: 0.8906\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2678 - binary_accuracy: 0.8984\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 956us/step - loss: 0.2666 - binary_accuracy: 0.8867\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.2421 - binary_accuracy: 0.9043\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 996us/step - loss: 0.2694 - binary_accuracy: 0.9062\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2365 - binary_accuracy: 0.9180\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 782us/step - loss: 0.2353 - binary_accuracy: 0.9199\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 969us/step - loss: 0.2381 - binary_accuracy: 0.9121\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2284 - binary_accuracy: 0.9082\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.3942 - binary_accuracy: 0.900 - 0s 912us/step - loss: 0.2381 - binary_accuracy: 0.9004\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 946us/step - loss: 0.2158 - binary_accuracy: 0.9219\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2225 - binary_accuracy: 0.9160\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2045 - binary_accuracy: 0.9160\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 979us/step - loss: 0.2200 - binary_accuracy: 0.9102\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 889us/step - loss: 0.2132 - binary_accuracy: 0.9160\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.2220 - binary_accuracy: 0.9121\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 891us/step - loss: 0.1841 - binary_accuracy: 0.9141\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 841us/step - loss: 0.2172 - binary_accuracy: 0.9199\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.2031 - binary_accuracy: 0.9199\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 899us/step - loss: 0.2050 - binary_accuracy: 0.9277\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 826us/step - loss: 0.2325 - binary_accuracy: 0.9141\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 899us/step - loss: 0.2000 - binary_accuracy: 0.9258\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 821us/step - loss: 0.2123 - binary_accuracy: 0.9277\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 865us/step - loss: 0.2465 - binary_accuracy: 0.9199\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1986 - binary_accuracy: 0.9160\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2216 - binary_accuracy: 0.9062\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2186 - binary_accuracy: 0.9102\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2033 - binary_accuracy: 0.9121\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 910us/step - loss: 0.1938 - binary_accuracy: 0.9258\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.1971 - binary_accuracy: 0.9316\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.0258 - binary_accuracy: 1.000 - 0s 954us/step - loss: 0.2052 - binary_accuracy: 0.9258\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1980 - binary_accuracy: 0.9219\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2018 - binary_accuracy: 0.9199\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1956 - binary_accuracy: 0.9297\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1934 - binary_accuracy: 0.9277\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1943 - binary_accuracy: 0.9316A: 0s - loss: 0.1890 - binary_accuracy: 0.935\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 822us/step - loss: 0.2007 - binary_accuracy: 0.9297\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 918us/step - loss: 0.1942 - binary_accuracy: 0.9277\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.1961 - binary_accuracy: 0.9141\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 899us/step - loss: 0.1864 - binary_accuracy: 0.9316\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2038 - binary_accuracy: 0.9141\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.1823 - binary_accuracy: 0.9277\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 751us/step - loss: 0.1897 - binary_accuracy: 0.9277\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 950us/step - loss: 0.1929 - binary_accuracy: 0.9180\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 801us/step - loss: 0.1752 - binary_accuracy: 0.9297\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 960us/step - loss: 0.1811 - binary_accuracy: 0.9180\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 841us/step - loss: 0.1964 - binary_accuracy: 0.9160\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 841us/step - loss: 0.1829 - binary_accuracy: 0.9238\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 924us/step - loss: 0.1969 - binary_accuracy: 0.9336\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 816us/step - loss: 0.1841 - binary_accuracy: 0.9258\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.1852 - binary_accuracy: 0.9180\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1855 - binary_accuracy: 0.9219\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.1799 - binary_accuracy: 0.9355\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1928 - binary_accuracy: 0.9316\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1886 - binary_accuracy: 0.9258\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 831us/step - loss: 0.1763 - binary_accuracy: 0.9414\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 841us/step - loss: 0.1746 - binary_accuracy: 0.9355\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.1855 - binary_accuracy: 0.9258\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 855us/step - loss: 0.1803 - binary_accuracy: 0.9316\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 981us/step - loss: 0.1821 - binary_accuracy: 0.9258\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 794us/step - loss: 0.1831 - binary_accuracy: 0.9414\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 932us/step - loss: 0.1915 - binary_accuracy: 0.9277\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 837us/step - loss: 0.1593 - binary_accuracy: 0.9395\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 871us/step - loss: 0.1959 - binary_accuracy: 0.9277\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 930us/step - loss: 0.1914 - binary_accuracy: 0.9395\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1639 - binary_accuracy: 0.9395\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1877 - binary_accuracy: 0.9238\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 950us/step - loss: 0.1708 - binary_accuracy: 0.9258\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.1669 - binary_accuracy: 0.9375\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 931us/step - loss: 0.1758 - binary_accuracy: 0.9258\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 950us/step - loss: 0.2323 - binary_accuracy: 0.9277\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.1843 - binary_accuracy: 0.9199\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 914us/step - loss: 0.1992 - binary_accuracy: 0.9336\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1932 - binary_accuracy: 0.9238\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2064 - binary_accuracy: 0.9238\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 975us/step - loss: 0.1873 - binary_accuracy: 0.9355\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.1805 - binary_accuracy: 0.9316\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.1817 - binary_accuracy: 0.9355\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 957us/step - loss: 0.1886 - binary_accuracy: 0.9277\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1672 - binary_accuracy: 0.9336\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 971us/step - loss: 0.1758 - binary_accuracy: 0.9219\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 936us/step - loss: 0.1720 - binary_accuracy: 0.9297\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 855us/step - loss: 0.1897 - binary_accuracy: 0.9297\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.1815 - binary_accuracy: 0.9219\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.1569 - binary_accuracy: 0.9336\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 986us/step - loss: 0.6326 - binary_accuracy: 0.6211\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 884us/step - loss: 0.5272 - binary_accuracy: 0.6484\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4978 - binary_accuracy: 0.6855\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4812 - binary_accuracy: 0.7188\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4574 - binary_accuracy: 0.7734\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4527 - binary_accuracy: 0.8223\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4247 - binary_accuracy: 0.8379\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4069 - binary_accuracy: 0.8359\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3869 - binary_accuracy: 0.8496\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3599 - binary_accuracy: 0.8730\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3753 - binary_accuracy: 0.8555\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3626 - binary_accuracy: 0.8691\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3083 - binary_accuracy: 0.8828\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2914 - binary_accuracy: 0.8848\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2763 - binary_accuracy: 0.8984\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2733 - binary_accuracy: 0.8828\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2518 - binary_accuracy: 0.9199\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2715 - binary_accuracy: 0.8809\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 917us/step - loss: 0.2419 - binary_accuracy: 0.9082\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2871 - binary_accuracy: 0.9043\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 898us/step - loss: 0.2689 - binary_accuracy: 0.9023\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 917us/step - loss: 0.2284 - binary_accuracy: 0.9219\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.2402 - binary_accuracy: 0.9141\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 976us/step - loss: 0.2347 - binary_accuracy: 0.9121\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 977us/step - loss: 0.2447 - binary_accuracy: 0.9121\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 882us/step - loss: 0.2510 - binary_accuracy: 0.9082\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2209 - binary_accuracy: 0.9082\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2193 - binary_accuracy: 0.9258\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2604 - binary_accuracy: 0.9180\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2130 - binary_accuracy: 0.9141A: 0s - loss: 0.2130 - binary_accuracy: 0.914\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 955us/step - loss: 0.2214 - binary_accuracy: 0.9082\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 998us/step - loss: 0.2311 - binary_accuracy: 0.9102\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2371 - binary_accuracy: 0.9082\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2077 - binary_accuracy: 0.9082\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2260 - binary_accuracy: 0.9277\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 984us/step - loss: 0.2130 - binary_accuracy: 0.9160\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.2115 - binary_accuracy: 0.9082\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 907us/step - loss: 0.2235 - binary_accuracy: 0.9004\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2053 - binary_accuracy: 0.9238\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.2271 - binary_accuracy: 0.9180\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2214 - binary_accuracy: 0.9180\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 936us/step - loss: 0.2265 - binary_accuracy: 0.9258\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 892us/step - loss: 0.2072 - binary_accuracy: 0.9277\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 909us/step - loss: 0.2088 - binary_accuracy: 0.9258\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2168 - binary_accuracy: 0.9043\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2193 - binary_accuracy: 0.9258\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2207 - binary_accuracy: 0.9141\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2122 - binary_accuracy: 0.9121\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 893us/step - loss: 0.1991 - binary_accuracy: 0.9277\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.2249 - binary_accuracy: 0.9102\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 969us/step - loss: 0.1971 - binary_accuracy: 0.9277\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1487 - binary_accuracy: 0.900 - 0s 938us/step - loss: 0.1970 - binary_accuracy: 0.9121\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2100 - binary_accuracy: 0.9121\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2099 - binary_accuracy: 0.9160\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2029 - binary_accuracy: 0.9277\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2112 - binary_accuracy: 0.9219\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2094 - binary_accuracy: 0.9082\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2197 - binary_accuracy: 0.9082\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 744us/step - loss: 0.1907 - binary_accuracy: 0.9180\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.1913 - binary_accuracy: 0.9238\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 921us/step - loss: 0.2111 - binary_accuracy: 0.9297\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 917us/step - loss: 0.2088 - binary_accuracy: 0.9121\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 852us/step - loss: 0.1862 - binary_accuracy: 0.9395\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 851us/step - loss: 0.1913 - binary_accuracy: 0.9277\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 911us/step - loss: 0.2014 - binary_accuracy: 0.9297\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 879us/step - loss: 0.1964 - binary_accuracy: 0.9180\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 956us/step - loss: 0.2263 - binary_accuracy: 0.9180\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2035 - binary_accuracy: 0.9199\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2073 - binary_accuracy: 0.9199\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2051 - binary_accuracy: 0.9238\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1859 - binary_accuracy: 0.9277\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2172 - binary_accuracy: 0.9219\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.1936 - binary_accuracy: 0.9258\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.1941 - binary_accuracy: 0.9258\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2455 - binary_accuracy: 0.8984\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 938us/step - loss: 0.1810 - binary_accuracy: 0.9277\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 954us/step - loss: 0.1887 - binary_accuracy: 0.9375\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.1863 - binary_accuracy: 0.9297\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1633 - binary_accuracy: 0.9316\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 891us/step - loss: 0.2175 - binary_accuracy: 0.9160\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2007 - binary_accuracy: 0.9238\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 806us/step - loss: 0.2308 - binary_accuracy: 0.9141\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2089 - binary_accuracy: 0.9160\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1792 - binary_accuracy: 0.9238\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2299 - binary_accuracy: 0.9160\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 964us/step - loss: 0.1773 - binary_accuracy: 0.9355\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 840us/step - loss: 0.2114 - binary_accuracy: 0.9199\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 971us/step - loss: 0.1882 - binary_accuracy: 0.9141\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 901us/step - loss: 0.1914 - binary_accuracy: 0.9199\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.1859 - binary_accuracy: 0.9375\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 957us/step - loss: 0.1923 - binary_accuracy: 0.9219\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 893us/step - loss: 0.2313 - binary_accuracy: 0.9219\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 883us/step - loss: 0.1934 - binary_accuracy: 0.9297\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.4205 - binary_accuracy: 0.900 - 0s 822us/step - loss: 0.1878 - binary_accuracy: 0.9297\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2478 - binary_accuracy: 0.9121\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1957 - binary_accuracy: 0.9316\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1725 - binary_accuracy: 0.9277\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1954 - binary_accuracy: 0.9238\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2022 - binary_accuracy: 0.9336\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 801us/step - loss: 0.2255 - binary_accuracy: 0.9180\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 880us/step - loss: 0.6384 - binary_accuracy: 0.6328\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.5350 - binary_accuracy: 0.6641\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4909 - binary_accuracy: 0.7305\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4315 - binary_accuracy: 0.7930\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3902 - binary_accuracy: 0.8477\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3880 - binary_accuracy: 0.8320\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3530 - binary_accuracy: 0.8516\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3213 - binary_accuracy: 0.8613\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 929us/step - loss: 0.3316 - binary_accuracy: 0.8613\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3115 - binary_accuracy: 0.8613\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2916 - binary_accuracy: 0.8750\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.3020 - binary_accuracy: 0.8828\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2714 - binary_accuracy: 0.8945\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.2936 - binary_accuracy: 0.8848\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 972us/step - loss: 0.2884 - binary_accuracy: 0.8711\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2626 - binary_accuracy: 0.8984\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 993us/step - loss: 0.2840 - binary_accuracy: 0.8750\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 859us/step - loss: 0.2446 - binary_accuracy: 0.9023\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2710 - binary_accuracy: 0.8945\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.2443 - binary_accuracy: 0.8906\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2382 - binary_accuracy: 0.9023\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 802us/step - loss: 0.2418 - binary_accuracy: 0.9043\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2488 - binary_accuracy: 0.8965\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.2177 - binary_accuracy: 0.9160\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 899us/step - loss: 0.2237 - binary_accuracy: 0.9062\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 848us/step - loss: 0.2222 - binary_accuracy: 0.9004\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 938us/step - loss: 0.2534 - binary_accuracy: 0.9043\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2317 - binary_accuracy: 0.9043\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2147 - binary_accuracy: 0.9141\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 877us/step - loss: 0.2157 - binary_accuracy: 0.9062\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2266 - binary_accuracy: 0.9102\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.2205 - binary_accuracy: 0.9102\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2102 - binary_accuracy: 0.9219\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 861us/step - loss: 0.2178 - binary_accuracy: 0.9141\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 998us/step - loss: 0.2146 - binary_accuracy: 0.9277\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 902us/step - loss: 0.2225 - binary_accuracy: 0.9160\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2057 - binary_accuracy: 0.9238\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2115 - binary_accuracy: 0.9043\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.1782 - binary_accuracy: 0.9355\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.2143 - binary_accuracy: 0.9102\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2247 - binary_accuracy: 0.9141\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 889us/step - loss: 0.1903 - binary_accuracy: 0.9316\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2075 - binary_accuracy: 0.9180\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 906us/step - loss: 0.1985 - binary_accuracy: 0.9082\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 870us/step - loss: 0.2024 - binary_accuracy: 0.9199\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.1984 - binary_accuracy: 0.9160\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1963 - binary_accuracy: 1.000 - 0s 890us/step - loss: 0.2256 - binary_accuracy: 0.9121\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 797us/step - loss: 0.2108 - binary_accuracy: 0.9180\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.1971 - binary_accuracy: 0.9180\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2075 - binary_accuracy: 0.9199\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2105 - binary_accuracy: 0.9121\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2076 - binary_accuracy: 0.9121\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.1925 - binary_accuracy: 0.9180\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 875us/step - loss: 0.1862 - binary_accuracy: 0.9316\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2116 - binary_accuracy: 0.9160\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 857us/step - loss: 0.2240 - binary_accuracy: 0.9160\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 955us/step - loss: 0.2039 - binary_accuracy: 0.9141\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.1958 - binary_accuracy: 0.9355\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.1947 - binary_accuracy: 0.9277\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 894us/step - loss: 0.1984 - binary_accuracy: 0.9219\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 821us/step - loss: 0.2060 - binary_accuracy: 0.9062\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 929us/step - loss: 0.3090 - binary_accuracy: 0.9160\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2148 - binary_accuracy: 0.9082\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 979us/step - loss: 0.2266 - binary_accuracy: 0.9121\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 942us/step - loss: 0.2103 - binary_accuracy: 0.9102\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.1931 - binary_accuracy: 0.9258\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 902us/step - loss: 0.2048 - binary_accuracy: 0.9238\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.2084 - binary_accuracy: 0.9277\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.2033 - binary_accuracy: 0.9219\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1882 - binary_accuracy: 0.9336\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 894us/step - loss: 0.2012 - binary_accuracy: 0.9238\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 821us/step - loss: 0.1903 - binary_accuracy: 0.9297\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1964 - binary_accuracy: 0.9160\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.1944 - binary_accuracy: 0.9238\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 938us/step - loss: 0.2060 - binary_accuracy: 0.9180\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2100 - binary_accuracy: 0.9160\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 894us/step - loss: 0.1961 - binary_accuracy: 0.9238\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 971us/step - loss: 0.1854 - binary_accuracy: 0.9258\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 918us/step - loss: 0.1965 - binary_accuracy: 0.9395\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 869us/step - loss: 0.2164 - binary_accuracy: 0.9141\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.1892 - binary_accuracy: 0.9297\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.1961 - binary_accuracy: 0.9258\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 899us/step - loss: 0.1924 - binary_accuracy: 0.9258\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 924us/step - loss: 0.2104 - binary_accuracy: 0.9102\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.1962 - binary_accuracy: 0.9238\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 917us/step - loss: 0.2003 - binary_accuracy: 0.9121\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 897us/step - loss: 0.1950 - binary_accuracy: 0.9062\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 853us/step - loss: 0.1932 - binary_accuracy: 0.9160\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 910us/step - loss: 0.1881 - binary_accuracy: 0.9258\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 872us/step - loss: 0.1921 - binary_accuracy: 0.9277\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 820us/step - loss: 0.2098 - binary_accuracy: 0.9180\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 920us/step - loss: 0.1837 - binary_accuracy: 0.9277\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 787us/step - loss: 0.1850 - binary_accuracy: 0.9258\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 898us/step - loss: 0.1999 - binary_accuracy: 0.9160\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1276 - binary_accuracy: 1.000 - 0s 839us/step - loss: 0.2079 - binary_accuracy: 0.9180\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 933us/step - loss: 0.1690 - binary_accuracy: 0.9336\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.1882 - binary_accuracy: 0.9199\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2302 - binary_accuracy: 0.9180\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1874 - binary_accuracy: 0.9258\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1904 - binary_accuracy: 0.9199\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 864us/step - loss: 0.6348 - binary_accuracy: 0.6686\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5430 - binary_accuracy: 0.7407\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4634 - binary_accuracy: 0.7895\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4356 - binary_accuracy: 0.8148\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4364 - binary_accuracy: 0.8129\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4139 - binary_accuracy: 0.8304\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4008 - binary_accuracy: 0.8207\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.3740 - binary_accuracy: 0.8402\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3724 - binary_accuracy: 0.8538\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 995us/step - loss: 0.3280 - binary_accuracy: 0.8869\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 969us/step - loss: 0.3237 - binary_accuracy: 0.8616\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3332 - binary_accuracy: 0.8791\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3083 - binary_accuracy: 0.8752\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3015 - binary_accuracy: 0.8830\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 956us/step - loss: 0.2973 - binary_accuracy: 0.8850\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3165 - binary_accuracy: 0.8869\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3009 - binary_accuracy: 0.8752\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 928us/step - loss: 0.2867 - binary_accuracy: 0.8830\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 863us/step - loss: 0.2690 - binary_accuracy: 0.8850\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 879us/step - loss: 0.2705 - binary_accuracy: 0.8967\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 918us/step - loss: 0.2718 - binary_accuracy: 0.8928\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 914us/step - loss: 0.2687 - binary_accuracy: 0.8967\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.2432 - binary_accuracy: 0.9064\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 940us/step - loss: 0.2610 - binary_accuracy: 0.8908\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2364 - binary_accuracy: 0.9123\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 802us/step - loss: 0.2357 - binary_accuracy: 0.9084\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2437 - binary_accuracy: 0.8908\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2445 - binary_accuracy: 0.8986A: 0s - loss: 0.2408 - binary_accuracy: 0.900\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2355 - binary_accuracy: 0.9045\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2327 - binary_accuracy: 0.9103\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2425 - binary_accuracy: 0.8967\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2424 - binary_accuracy: 0.9084\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.2043 - binary_accuracy: 0.9240\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2395 - binary_accuracy: 0.9084\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 755us/step - loss: 0.2316 - binary_accuracy: 0.8947\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2163 - binary_accuracy: 0.9123\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.2992 - binary_accuracy: 0.900 - 0s 878us/step - loss: 0.2371 - binary_accuracy: 0.9103\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.2449 - binary_accuracy: 0.8967\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 951us/step - loss: 0.2187 - binary_accuracy: 0.9103\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.2233 - binary_accuracy: 0.9103\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 860us/step - loss: 0.2239 - binary_accuracy: 0.9181\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 992us/step - loss: 0.2081 - binary_accuracy: 0.9162\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 802us/step - loss: 0.2490 - binary_accuracy: 0.9103\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 931us/step - loss: 0.2282 - binary_accuracy: 0.8967\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 850us/step - loss: 0.2212 - binary_accuracy: 0.9084\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 977us/step - loss: 0.2048 - binary_accuracy: 0.9201\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 897us/step - loss: 0.2202 - binary_accuracy: 0.9084\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 934us/step - loss: 0.2194 - binary_accuracy: 0.9064\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 813us/step - loss: 0.2498 - binary_accuracy: 0.9006\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.2447 - binary_accuracy: 0.9006\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2217 - binary_accuracy: 0.9064\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2292 - binary_accuracy: 0.9045\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2252 - binary_accuracy: 0.9220\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 904us/step - loss: 0.2177 - binary_accuracy: 0.9162\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2218 - binary_accuracy: 0.9201\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 915us/step - loss: 0.2240 - binary_accuracy: 0.9045\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2526 - binary_accuracy: 0.9025\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2394 - binary_accuracy: 0.9045\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2174 - binary_accuracy: 0.9162\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.2106 - binary_accuracy: 0.9103\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 926us/step - loss: 0.2121 - binary_accuracy: 0.9045\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1255 - binary_accuracy: 0.900 - 0s 975us/step - loss: 0.2399 - binary_accuracy: 0.9025\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 955us/step - loss: 0.2264 - binary_accuracy: 0.9162\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2227 - binary_accuracy: 0.9084\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2231 - binary_accuracy: 0.9064\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2206 - binary_accuracy: 0.9084\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 916us/step - loss: 0.2829 - binary_accuracy: 0.9142\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 855us/step - loss: 0.2240 - binary_accuracy: 0.9064\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.2355 - binary_accuracy: 0.9181\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 897us/step - loss: 0.1915 - binary_accuracy: 0.9201\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 875us/step - loss: 0.2421 - binary_accuracy: 0.9084\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 998us/step - loss: 0.2008 - binary_accuracy: 0.9181\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 895us/step - loss: 0.2375 - binary_accuracy: 0.9181\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 896us/step - loss: 0.2127 - binary_accuracy: 0.9103\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 905us/step - loss: 0.2289 - binary_accuracy: 0.9220\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2636 - binary_accuracy: 0.8889\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2195 - binary_accuracy: 0.9025\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.2558 - binary_accuracy: 0.9045\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2720 - binary_accuracy: 0.9162\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.3083 - binary_accuracy: 0.9162\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2670 - binary_accuracy: 0.9025\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 880us/step - loss: 0.2729 - binary_accuracy: 0.9084\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.2151 - binary_accuracy: 0.9181\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 841us/step - loss: 0.2064 - binary_accuracy: 0.9162\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2021 - binary_accuracy: 0.9259\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2739 - binary_accuracy: 0.9201\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 889us/step - loss: 0.2186 - binary_accuracy: 0.9142\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.1943 - binary_accuracy: 0.9201\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.2105 - binary_accuracy: 0.9123\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.2074 - binary_accuracy: 0.9123\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.1924 - binary_accuracy: 0.9142A: 0s - loss: 0.1924 - binary_accuracy: 0.914\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2033 - binary_accuracy: 0.9201\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2429 - binary_accuracy: 0.9025\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2236 - binary_accuracy: 0.9064\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.2579 - binary_accuracy: 0.9064\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 841us/step - loss: 0.2409 - binary_accuracy: 0.9103\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 828us/step - loss: 0.2483 - binary_accuracy: 0.9064\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 919us/step - loss: 0.2354 - binary_accuracy: 0.9123\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.3777 - binary_accuracy: 0.8869\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 821us/step - loss: 0.2450 - binary_accuracy: 0.9025\n"
     ]
    }
   ],
   "source": [
    "resultados = cross_val_score(estimator = classificador, X = previsores, y = classe, cv = 10, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "media = resultados.mean()\n",
    "desvio = resultados.std()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
