{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "previsores = pd.read_csv('entradas_breast.csv')\n",
    "classe = pd.read_csv('saidas_breast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "previsores_treino, previsores_teste, classe_treino, classe_teste = train_test_split(previsores, classe, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construção e entendimento da estrutura da rede neural\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "classificador = Sequential()\n",
    "# neurônios de entrada\n",
    "classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer='random_uniform', input_dim = 30))\n",
    "classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer='random_uniform'))\n",
    "classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer='random_uniform'))\n",
    "classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer='random_uniform'))\n",
    "classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer='random_uniform'))\n",
    "# neurônios de saída\n",
    "classificador.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 797us/step - loss: 0.6345 - binary_accuracy: 0.6432\n",
      "Epoch 2/100\n",
      "43/43 [==============================] - 0s 737us/step - loss: 0.5251 - binary_accuracy: 0.6948\n",
      "Epoch 3/100\n",
      "43/43 [==============================] - 0s 712us/step - loss: 0.5075 - binary_accuracy: 0.6831\n",
      "Epoch 4/100\n",
      "43/43 [==============================] - 0s 756us/step - loss: 0.4930 - binary_accuracy: 0.6831\n",
      "Epoch 5/100\n",
      "43/43 [==============================] - 0s 760us/step - loss: 0.4836 - binary_accuracy: 0.7066\n",
      "Epoch 6/100\n",
      "43/43 [==============================] - 0s 771us/step - loss: 0.4704 - binary_accuracy: 0.7160\n",
      "Epoch 7/100\n",
      "43/43 [==============================] - 0s 742us/step - loss: 0.4492 - binary_accuracy: 0.8052\n",
      "Epoch 8/100\n",
      "43/43 [==============================] - 0s 712us/step - loss: 0.4193 - binary_accuracy: 0.8216\n",
      "Epoch 9/100\n",
      "43/43 [==============================] - 0s 689us/step - loss: 0.3984 - binary_accuracy: 0.8263\n",
      "Epoch 10/100\n",
      "43/43 [==============================] - 0s 712us/step - loss: 0.3727 - binary_accuracy: 0.8615\n",
      "Epoch 11/100\n",
      "43/43 [==============================] - 0s 784us/step - loss: 0.3567 - binary_accuracy: 0.8545\n",
      "Epoch 12/100\n",
      "43/43 [==============================] - 0s 855us/step - loss: 0.3389 - binary_accuracy: 0.8685\n",
      "Epoch 13/100\n",
      "43/43 [==============================] - 0s 712us/step - loss: 0.3198 - binary_accuracy: 0.8709\n",
      "Epoch 14/100\n",
      "43/43 [==============================] - 0s 733us/step - loss: 0.3039 - binary_accuracy: 0.8826\n",
      "Epoch 15/100\n",
      "43/43 [==============================] - 0s 689us/step - loss: 0.2944 - binary_accuracy: 0.8944\n",
      "Epoch 16/100\n",
      "43/43 [==============================] - 0s 688us/step - loss: 0.2823 - binary_accuracy: 0.8826\n",
      "Epoch 17/100\n",
      "43/43 [==============================] - 0s 689us/step - loss: 0.2854 - binary_accuracy: 0.9038\n",
      "Epoch 18/100\n",
      "43/43 [==============================] - 0s 769us/step - loss: 0.2684 - binary_accuracy: 0.8873\n",
      "Epoch 19/100\n",
      "43/43 [==============================] - 0s 831us/step - loss: 0.2720 - binary_accuracy: 0.8967\n",
      "Epoch 20/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2682 - binary_accuracy: 0.8920\n",
      "Epoch 21/100\n",
      "43/43 [==============================] - 0s 797us/step - loss: 0.2548 - binary_accuracy: 0.9014\n",
      "Epoch 22/100\n",
      "43/43 [==============================] - 0s 807us/step - loss: 0.2443 - binary_accuracy: 0.9131\n",
      "Epoch 23/100\n",
      "43/43 [==============================] - 0s 760us/step - loss: 0.2372 - binary_accuracy: 0.9014\n",
      "Epoch 24/100\n",
      "43/43 [==============================] - 0s 882us/step - loss: 0.2422 - binary_accuracy: 0.9108\n",
      "Epoch 25/100\n",
      "43/43 [==============================] - 0s 760us/step - loss: 0.2217 - binary_accuracy: 0.9108\n",
      "Epoch 26/100\n",
      "43/43 [==============================] - 0s 713us/step - loss: 0.2357 - binary_accuracy: 0.8991\n",
      "Epoch 27/100\n",
      "43/43 [==============================] - 0s 812us/step - loss: 0.2305 - binary_accuracy: 0.9131\n",
      "Epoch 28/100\n",
      "43/43 [==============================] - 0s 752us/step - loss: 0.2279 - binary_accuracy: 0.9085\n",
      "Epoch 29/100\n",
      "43/43 [==============================] - 0s 766us/step - loss: 0.2413 - binary_accuracy: 0.9038\n",
      "Epoch 30/100\n",
      "43/43 [==============================] - 0s 868us/step - loss: 0.2179 - binary_accuracy: 0.9038\n",
      "Epoch 31/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2140 - binary_accuracy: 0.9131\n",
      "Epoch 32/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2436 - binary_accuracy: 0.9108\n",
      "Epoch 33/100\n",
      "43/43 [==============================] - 0s 978us/step - loss: 0.2506 - binary_accuracy: 0.9061\n",
      "Epoch 34/100\n",
      "43/43 [==============================] - 0s 854us/step - loss: 0.2137 - binary_accuracy: 0.9178\n",
      "Epoch 35/100\n",
      "43/43 [==============================] - 0s 788us/step - loss: 0.2342 - binary_accuracy: 0.9014\n",
      "Epoch 36/100\n",
      "43/43 [==============================] - 0s 838us/step - loss: 0.2122 - binary_accuracy: 0.9131\n",
      "Epoch 37/100\n",
      "43/43 [==============================] - 0s 730us/step - loss: 0.2051 - binary_accuracy: 0.9225\n",
      "Epoch 38/100\n",
      "43/43 [==============================] - 0s 736us/step - loss: 0.2070 - binary_accuracy: 0.9108\n",
      "Epoch 39/100\n",
      "43/43 [==============================] - 0s 840us/step - loss: 0.2243 - binary_accuracy: 0.9108\n",
      "Epoch 40/100\n",
      "43/43 [==============================] - 0s 830us/step - loss: 0.2481 - binary_accuracy: 0.9155\n",
      "Epoch 41/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2123 - binary_accuracy: 0.9131\n",
      "Epoch 42/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1977 - binary_accuracy: 0.9202\n",
      "Epoch 43/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1756 - binary_accuracy: 0.9225\n",
      "Epoch 44/100\n",
      "43/43 [==============================] - 0s 855us/step - loss: 0.2146 - binary_accuracy: 0.9225\n",
      "Epoch 45/100\n",
      "43/43 [==============================] - 0s 832us/step - loss: 0.2245 - binary_accuracy: 0.9225\n",
      "Epoch 46/100\n",
      "43/43 [==============================] - 0s 803us/step - loss: 0.1772 - binary_accuracy: 0.9319\n",
      "Epoch 47/100\n",
      "43/43 [==============================] - 0s 832us/step - loss: 0.2165 - binary_accuracy: 0.9085\n",
      "Epoch 48/100\n",
      "43/43 [==============================] - 0s 830us/step - loss: 0.2156 - binary_accuracy: 0.9155\n",
      "Epoch 49/100\n",
      "43/43 [==============================] - 0s 807us/step - loss: 0.2225 - binary_accuracy: 0.9155\n",
      "Epoch 50/100\n",
      "43/43 [==============================] - 0s 828us/step - loss: 0.1982 - binary_accuracy: 0.9178\n",
      "Epoch 51/100\n",
      "43/43 [==============================] - 0s 789us/step - loss: 0.1943 - binary_accuracy: 0.9085\n",
      "Epoch 52/100\n",
      "43/43 [==============================] - 0s 926us/step - loss: 0.1683 - binary_accuracy: 0.9249\n",
      "Epoch 53/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1918 - binary_accuracy: 0.9296\n",
      "Epoch 54/100\n",
      "43/43 [==============================] - 0s 764us/step - loss: 0.2108 - binary_accuracy: 0.9249\n",
      "Epoch 55/100\n",
      "43/43 [==============================] - 0s 736us/step - loss: 0.2327 - binary_accuracy: 0.9249\n",
      "Epoch 56/100\n",
      "43/43 [==============================] - 0s 778us/step - loss: 0.2363 - binary_accuracy: 0.9319\n",
      "Epoch 57/100\n",
      "43/43 [==============================] - 0s 760us/step - loss: 0.1854 - binary_accuracy: 0.9225\n",
      "Epoch 58/100\n",
      "43/43 [==============================] - 0s 888us/step - loss: 0.2478 - binary_accuracy: 0.9178\n",
      "Epoch 59/100\n",
      "43/43 [==============================] - 0s 855us/step - loss: 0.2706 - binary_accuracy: 0.9343\n",
      "Epoch 60/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1917 - binary_accuracy: 0.9296\n",
      "Epoch 61/100\n",
      "43/43 [==============================] - 0s 855us/step - loss: 0.1929 - binary_accuracy: 0.9202\n",
      "Epoch 62/100\n",
      "43/43 [==============================] - 0s 759us/step - loss: 0.1995 - binary_accuracy: 0.9202\n",
      "Epoch 63/100\n",
      "43/43 [==============================] - 0s 762us/step - loss: 0.2930 - binary_accuracy: 0.9178\n",
      "Epoch 64/100\n",
      "43/43 [==============================] - 0s 807us/step - loss: 0.1822 - binary_accuracy: 0.9296\n",
      "Epoch 65/100\n",
      "43/43 [==============================] - 0s 791us/step - loss: 0.2205 - binary_accuracy: 0.9202\n",
      "Epoch 66/100\n",
      "43/43 [==============================] - 0s 926us/step - loss: 0.1629 - binary_accuracy: 0.9249\n",
      "Epoch 67/100\n",
      "43/43 [==============================] - 0s 760us/step - loss: 0.1995 - binary_accuracy: 0.9225\n",
      "Epoch 68/100\n",
      "43/43 [==============================] - 0s 784us/step - loss: 0.1764 - binary_accuracy: 0.9319\n",
      "Epoch 69/100\n",
      "43/43 [==============================] - 0s 831us/step - loss: 0.1812 - binary_accuracy: 0.9296\n",
      "Epoch 70/100\n",
      "43/43 [==============================] - 0s 784us/step - loss: 0.2001 - binary_accuracy: 0.9131\n",
      "Epoch 71/100\n",
      "43/43 [==============================] - 0s 807us/step - loss: 0.1761 - binary_accuracy: 0.9343\n",
      "Epoch 72/100\n",
      "43/43 [==============================] - 0s 807us/step - loss: 0.1724 - binary_accuracy: 0.9296\n",
      "Epoch 73/100\n",
      "43/43 [==============================] - 0s 784us/step - loss: 0.1800 - binary_accuracy: 0.9178\n",
      "Epoch 74/100\n",
      "43/43 [==============================] - 0s 831us/step - loss: 0.2926 - binary_accuracy: 0.9296\n",
      "Epoch 75/100\n",
      "43/43 [==============================] - 0s 815us/step - loss: 0.2204 - binary_accuracy: 0.9366\n",
      "Epoch 76/100\n",
      "43/43 [==============================] - 0s 894us/step - loss: 0.1904 - binary_accuracy: 0.9249\n",
      "Epoch 77/100\n",
      "43/43 [==============================] - 0s 790us/step - loss: 0.2412 - binary_accuracy: 0.9202\n",
      "Epoch 78/100\n",
      "43/43 [==============================] - 0s 798us/step - loss: 0.2008 - binary_accuracy: 0.9225\n",
      "Epoch 79/100\n",
      "43/43 [==============================] - 0s 828us/step - loss: 0.1752 - binary_accuracy: 0.9272\n",
      "Epoch 80/100\n",
      "43/43 [==============================] - 0s 826us/step - loss: 0.1816 - binary_accuracy: 0.9272\n",
      "Epoch 81/100\n",
      "43/43 [==============================] - 0s 761us/step - loss: 0.1721 - binary_accuracy: 0.9319\n",
      "Epoch 82/100\n",
      "43/43 [==============================] - 0s 761us/step - loss: 0.1634 - binary_accuracy: 0.9366\n",
      "Epoch 83/100\n",
      "43/43 [==============================] - 0s 784us/step - loss: 0.3806 - binary_accuracy: 0.9225\n",
      "Epoch 84/100\n",
      "43/43 [==============================] - 0s 758us/step - loss: 0.2852 - binary_accuracy: 0.9178\n",
      "Epoch 85/100\n",
      "43/43 [==============================] - 0s 801us/step - loss: 0.1823 - binary_accuracy: 0.9319\n",
      "Epoch 86/100\n",
      "43/43 [==============================] - 0s 779us/step - loss: 0.1780 - binary_accuracy: 0.9390\n",
      "Epoch 87/100\n",
      "43/43 [==============================] - 0s 784us/step - loss: 0.2856 - binary_accuracy: 0.9319\n",
      "Epoch 88/100\n",
      "43/43 [==============================] - 0s 807us/step - loss: 0.1704 - binary_accuracy: 0.9390\n",
      "Epoch 89/100\n",
      "43/43 [==============================] - 0s 814us/step - loss: 0.1567 - binary_accuracy: 0.9390\n",
      "Epoch 90/100\n",
      "43/43 [==============================] - 0s 810us/step - loss: 0.1583 - binary_accuracy: 0.9272\n",
      "Epoch 91/100\n",
      "43/43 [==============================] - 0s 760us/step - loss: 0.2537 - binary_accuracy: 0.9319\n",
      "Epoch 92/100\n",
      "43/43 [==============================] - 0s 807us/step - loss: 0.1644 - binary_accuracy: 0.9296\n",
      "Epoch 93/100\n",
      "43/43 [==============================] - 0s 867us/step - loss: 0.2165 - binary_accuracy: 0.9225\n",
      "Epoch 94/100\n",
      "43/43 [==============================] - 0s 902us/step - loss: 0.3366 - binary_accuracy: 0.9178\n",
      "Epoch 95/100\n",
      "43/43 [==============================] - 0s 900us/step - loss: 0.1575 - binary_accuracy: 0.9319\n",
      "Epoch 96/100\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.1850 - binary_accuracy: 0.9319\n",
      "Epoch 97/100\n",
      "43/43 [==============================] - 0s 819us/step - loss: 0.5361 - binary_accuracy: 0.9460\n",
      "Epoch 98/100\n",
      "43/43 [==============================] - 0s 721us/step - loss: 0.1770 - binary_accuracy: 0.9272\n",
      "Epoch 99/100\n",
      "43/43 [==============================] - 0s 776us/step - loss: 0.2842 - binary_accuracy: 0.9296\n",
      "Epoch 100/100\n",
      "43/43 [==============================] - 0s 782us/step - loss: 0.1826 - binary_accuracy: 0.9249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x266f7629c40>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configuração e execução da rede neural\n",
    "otimizador = tf.keras.optimizers.Adam(lr = 0.001, beta_1 = 0.0001, clipvalue = 0.5) \n",
    "classificador.compile(optimizer = otimizador, loss = 'binary_crossentropy',\n",
    "                      metrics = ['binary_accuracy'])\n",
    "# classificador.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
    "\n",
    "classificador.fit(previsores_treino, classe_treino, batch_size =10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-8.55253413e-02,  4.62662205e-02,  2.02239424e-01,\n",
      "        -1.23227693e-01, -1.34493858e-01,  7.63239637e-02,\n",
      "         6.50940612e-02,  7.66571164e-02, -7.44200870e-03,\n",
      "         1.15897685e-01,  2.27871925e-01, -4.80484702e-02,\n",
      "         5.37119582e-02, -3.07369959e-02, -2.07368974e-02,\n",
      "        -1.56081095e-02],\n",
      "       [ 3.26227516e-01,  3.16685796e-01, -1.50946051e-01,\n",
      "         1.20896116e-01, -3.73729438e-01, -6.15528189e-02,\n",
      "        -1.95133299e-01,  1.02986097e-02,  1.42986208e-01,\n",
      "        -1.54410638e-02, -1.12442434e-01, -7.68995136e-02,\n",
      "         2.57478710e-02,  1.42639130e-01,  9.27382037e-02,\n",
      "        -3.03987749e-02],\n",
      "       [-2.47706547e-01, -2.35739872e-01, -9.98655185e-02,\n",
      "        -3.19960505e-01, -1.13464221e-01,  2.24817991e-01,\n",
      "        -1.57901391e-01,  5.12407348e-02,  7.81885162e-02,\n",
      "        -9.52479020e-02, -7.35895559e-02,  1.28909588e-01,\n",
      "         9.20657963e-02, -2.33472586e-01,  1.63910940e-01,\n",
      "        -4.40466404e-03],\n",
      "       [-6.95512891e-02, -3.78196947e-02, -1.15559980e-01,\n",
      "        -9.36788321e-02,  9.01730210e-02,  7.73479119e-02,\n",
      "        -1.90895677e-01, -6.22415543e-02, -3.23594473e-02,\n",
      "        -4.10771109e-02, -1.61393955e-01,  2.44723126e-01,\n",
      "         2.97618024e-02, -7.76795000e-02, -2.11911332e-02,\n",
      "        -1.52410381e-02],\n",
      "       [ 1.91693887e-01,  5.57291470e-02, -1.66224912e-01,\n",
      "         1.03481300e-01, -1.11057602e-01, -1.12386651e-01,\n",
      "        -1.53094873e-01,  2.12413654e-01, -7.26794004e-02,\n",
      "         3.16617861e-02,  1.14075609e-01, -1.07628480e-02,\n",
      "         8.75441283e-02,  2.11786389e-01,  1.14106704e-02,\n",
      "         2.90394910e-02],\n",
      "       [ 1.36355549e-01, -9.88849923e-02, -7.51223266e-02,\n",
      "         1.02831006e-01, -3.81893516e-02,  9.98426229e-02,\n",
      "         5.39185479e-03,  1.29866526e-01,  4.22962271e-02,\n",
      "         1.07253946e-01, -2.93417387e-02,  1.71752721e-02,\n",
      "         1.82908207e-01, -1.52238443e-01,  7.55137801e-02,\n",
      "        -2.63855457e-02],\n",
      "       [ 5.40129207e-02, -1.42250545e-02, -8.64259154e-02,\n",
      "         1.64741769e-01,  1.27857447e-01,  8.08080584e-02,\n",
      "        -1.95310041e-02,  5.77228554e-02, -6.49976730e-02,\n",
      "         1.49447069e-01, -4.22698632e-02,  9.57053006e-02,\n",
      "         1.52192518e-01, -4.82635349e-02,  6.50292188e-02,\n",
      "         3.07312347e-02],\n",
      "       [-3.62274796e-01, -1.89808786e-01,  5.11555597e-02,\n",
      "        -2.34993562e-01, -6.03466146e-02,  2.67311901e-01,\n",
      "         1.31737832e-02,  5.55961095e-02,  3.39310952e-02,\n",
      "        -1.67560905e-01, -1.82239845e-01,  3.14983577e-02,\n",
      "        -1.99608301e-04, -2.98782349e-01,  1.01942971e-01,\n",
      "        -3.84814516e-02],\n",
      "       [-1.88906118e-01, -2.06036922e-02,  5.30006783e-03,\n",
      "         7.68620148e-02,  1.12153236e-02, -1.11646962e-03,\n",
      "         2.61790734e-02,  7.49690738e-03,  5.18516824e-02,\n",
      "        -8.92939940e-02, -4.22935076e-02, -1.97186559e-01,\n",
      "        -4.95579541e-02, -2.68484689e-02, -1.48021162e-01,\n",
      "         4.50080745e-02],\n",
      "       [-1.20545588e-01,  2.70579278e-01, -7.10752681e-02,\n",
      "        -2.00082228e-01, -6.31390736e-02,  1.56232640e-01,\n",
      "        -9.22130719e-02, -2.26615146e-02,  2.13565920e-02,\n",
      "        -3.75207961e-01, -3.04778486e-01,  1.34609953e-01,\n",
      "        -1.79292392e-02, -1.29698858e-01,  2.81393886e-01,\n",
      "         1.04319565e-02],\n",
      "       [-4.81610410e-02, -6.72841519e-02,  1.79555323e-02,\n",
      "         3.35415117e-02, -1.19670764e-01, -1.17898121e-01,\n",
      "         1.62927449e-01, -4.72581573e-02, -7.55027011e-02,\n",
      "        -6.29338622e-02,  4.00253870e-02, -2.45039329e-01,\n",
      "        -1.85889583e-02, -4.01688479e-02,  2.01606676e-01,\n",
      "         8.79774243e-03],\n",
      "       [-1.11346589e-02, -4.33007404e-02,  1.04576603e-01,\n",
      "        -1.86388940e-02, -2.61922121e-01, -2.99107824e-02,\n",
      "         2.80103087e-02,  9.82942432e-02,  9.62981209e-03,\n",
      "         5.73862121e-02,  1.04161903e-01, -2.35202417e-01,\n",
      "         6.14063777e-02, -7.42854252e-02,  3.59264202e-03,\n",
      "        -1.76403299e-02],\n",
      "       [ 7.85485609e-05,  1.32323790e-03,  5.58178239e-02,\n",
      "         1.74684392e-03,  5.21771684e-02,  2.69537121e-02,\n",
      "         9.34086815e-02, -3.47862504e-02, -1.96076687e-02,\n",
      "        -1.38703280e-03,  3.15173268e-02,  1.00842513e-01,\n",
      "        -2.11671907e-02,  3.13267559e-02, -9.68952775e-02,\n",
      "        -1.38945356e-02],\n",
      "       [ 3.41438740e-01,  3.54504168e-01,  4.78883445e-01,\n",
      "         1.07883617e-01, -3.74842018e-01, -2.94441469e-02,\n",
      "        -2.89306521e-01, -2.99537390e-01, -1.97400935e-02,\n",
      "         4.17124659e-01,  4.19219702e-01, -3.52034509e-01,\n",
      "         3.57476383e-01,  2.64138848e-01,  1.16505707e-02,\n",
      "        -1.01400726e-02],\n",
      "       [ 5.31469226e-01,  4.44371670e-01,  9.70096420e-03,\n",
      "         1.80864230e-01, -3.10766131e-01, -5.42463176e-02,\n",
      "        -1.14316195e-01, -1.45757413e-02,  1.26033381e-01,\n",
      "         1.87741548e-01,  1.70254692e-01, -1.60474718e-01,\n",
      "         1.04815863e-01,  2.71515399e-01, -3.95644596e-03,\n",
      "        -1.71031952e-02],\n",
      "       [ 5.57725549e-01,  1.24456614e-01,  6.65698647e-01,\n",
      "         1.56671330e-01, -4.26060975e-01, -2.13129640e-01,\n",
      "         2.07958907e-01,  4.09388006e-01, -1.04383007e-01,\n",
      "         5.92458427e-01,  8.34954202e-01, -4.65959072e-01,\n",
      "         4.48914647e-01,  4.20828074e-01, -2.24303827e-01,\n",
      "         3.26757319e-02],\n",
      "       [-2.78944165e-01, -3.15614700e-01,  1.11116640e-01,\n",
      "        -2.96826661e-01, -2.19443798e-01,  2.06272587e-01,\n",
      "        -1.12043053e-01,  6.16175607e-02, -5.44898119e-03,\n",
      "        -2.38137152e-02, -1.28505617e-01,  2.07996085e-01,\n",
      "         9.62194949e-02, -1.70490608e-01,  1.77248180e-01,\n",
      "        -2.31213495e-03],\n",
      "       [-3.63635778e-01, -4.53541636e-01,  3.43057811e-02,\n",
      "        -4.26000535e-01,  2.55623966e-01,  2.64749795e-01,\n",
      "        -4.13793102e-02,  1.56405225e-01, -2.08289213e-02,\n",
      "        -6.47167638e-02,  3.37279029e-02,  4.18765038e-01,\n",
      "         1.41931385e-01, -5.34791589e-01,  2.33594570e-02,\n",
      "         3.67319323e-02],\n",
      "       [ 3.89343977e-01,  1.97053269e-01, -7.01042637e-02,\n",
      "        -6.82372823e-02,  3.81612360e-01, -1.36119619e-01,\n",
      "        -8.46346542e-02, -1.64904803e-01, -3.70872952e-02,\n",
      "        -1.51995540e-01, -8.71463940e-02,  4.39325005e-01,\n",
      "        -2.07323223e-01, -8.28245133e-02,  1.34460077e-01,\n",
      "         4.64954711e-02],\n",
      "       [ 6.47683918e-01,  4.99917179e-01, -8.59147906e-02,\n",
      "         5.74383736e-01, -2.66105346e-02, -2.97111005e-01,\n",
      "        -4.81519140e-02,  1.10042013e-01,  4.65914086e-02,\n",
      "         2.88865805e-01,  1.71699509e-01, -2.04092845e-01,\n",
      "         9.90025476e-02,  4.66405064e-01,  5.82701303e-02,\n",
      "        -4.31678779e-02],\n",
      "       [-4.18936135e-03,  1.16454624e-01,  1.88584730e-01,\n",
      "        -8.93641859e-02, -2.36763254e-01, -1.23344245e-03,\n",
      "        -2.09902748e-01,  2.50612106e-03, -1.47257922e-02,\n",
      "         9.93966758e-02,  1.80372417e-01, -6.26999661e-02,\n",
      "        -5.35161868e-02,  4.49586548e-02,  4.22167918e-03,\n",
      "        -4.70510870e-03],\n",
      "       [ 4.14238513e-01,  4.20864016e-01, -2.23596230e-01,\n",
      "         3.31164390e-01, -4.55386490e-01, -1.43385023e-01,\n",
      "        -2.68327445e-01, -8.73422325e-02,  8.46148878e-02,\n",
      "        -5.39335050e-02, -1.70867696e-01, -3.92343588e-02,\n",
      "        -7.28460476e-02,  3.38337690e-01,  1.05803959e-01,\n",
      "         3.42449211e-02],\n",
      "       [-1.57347336e-01, -1.37510180e-01, -8.95083323e-02,\n",
      "        -1.39248744e-01, -1.30036011e-01,  1.61752164e-01,\n",
      "        -2.64604777e-01, -5.66847883e-02,  3.50679159e-02,\n",
      "        -9.53733996e-02, -1.22616678e-01,  4.55097295e-02,\n",
      "        -1.78833082e-02, -1.56311259e-01,  1.55573294e-01,\n",
      "        -3.37552316e-02],\n",
      "       [ 1.04833014e-01,  1.50175005e-01, -2.02590421e-01,\n",
      "         1.22992873e-01,  8.23360384e-02, -3.00918855e-02,\n",
      "        -1.87290654e-01, -9.64815244e-02, -5.90907782e-02,\n",
      "        -6.00870885e-02, -1.21518746e-01,  1.50590807e-01,\n",
      "        -1.43973485e-01,  1.35708228e-01, -5.82631640e-02,\n",
      "        -4.10766527e-03],\n",
      "       [-1.07700147e-01,  1.22180082e-01, -7.92313293e-02,\n",
      "        -3.93536203e-02, -2.12590229e-02, -3.44964154e-02,\n",
      "        -1.48148045e-01,  1.02806389e-01, -2.60675754e-02,\n",
      "         1.38985012e-02,  5.02198823e-02,  1.16053633e-01,\n",
      "        -4.41419967e-02, -8.73178095e-02, -1.21458760e-02,\n",
      "        -1.97391864e-02],\n",
      "       [-3.64749953e-02, -2.24988051e-02,  1.04010008e-01,\n",
      "         9.43908021e-02, -8.04633349e-02, -6.14941306e-02,\n",
      "         3.71148735e-01,  1.06021240e-02,  8.87112021e-02,\n",
      "         1.40356407e-01,  3.11536461e-01, -2.96587586e-01,\n",
      "         4.99464273e-02, -1.28844067e-01, -2.88506150e-02,\n",
      "        -1.36755407e-04],\n",
      "       [-2.81584799e-01, -4.68637981e-02, -5.88342138e-02,\n",
      "         7.73361400e-02, -2.80969858e-01, -7.34123439e-02,\n",
      "        -9.83818322e-02, -1.06657758e-01, -3.38417403e-02,\n",
      "        -9.83279198e-02, -1.75051570e-01, -1.18502647e-01,\n",
      "        -2.50123609e-02, -4.90256324e-02, -1.14585757e-01,\n",
      "        -3.45741995e-02],\n",
      "       [-1.67741537e-01, -4.54827510e-02,  2.03005359e-01,\n",
      "         1.06302485e-01, -1.38134196e-01, -1.65050879e-01,\n",
      "         3.51085097e-01, -2.24839896e-01, -4.60397378e-02,\n",
      "         3.55477810e-01,  8.70373398e-02, -1.97214201e-01,\n",
      "        -9.43562537e-02,  1.28728911e-01, -1.21825866e-01,\n",
      "        -3.05783041e-02],\n",
      "       [ 7.01030670e-03, -1.33670839e-02, -1.92120112e-02,\n",
      "         7.91079700e-02,  1.18920065e-01, -1.62777141e-01,\n",
      "        -1.94121882e-01, -2.07079381e-01, -5.23118302e-02,\n",
      "        -1.29442617e-01,  8.45965277e-03,  3.31892781e-02,\n",
      "        -1.71717480e-01, -6.90697581e-02, -1.40768841e-01,\n",
      "        -1.54197589e-02],\n",
      "       [ 3.93812060e-01,  3.29192042e-01, -1.35626286e-01,\n",
      "         3.87781590e-01,  1.67519987e-01, -3.27871591e-01,\n",
      "        -1.88325375e-01, -1.29978180e-01, -1.71792567e-01,\n",
      "        -4.15619984e-02, -1.08755976e-02,  1.09548882e-01,\n",
      "        -1.50016055e-01,  4.96936411e-01, -2.38433778e-01,\n",
      "        -4.43536304e-02]], dtype=float32), array([-0.406301  , -0.36635396,  0.00728294, -0.5681956 , -0.14065757,\n",
      "        0.41926137, -0.09727144,  0.10743546,  0.06703836, -0.11895609,\n",
      "       -0.12678154,  0.23866068,  0.14715229, -0.49065366,  0.11231199,\n",
      "        0.        ], dtype=float32)]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "pesos0 = classificador.layers[0].get_weights()\n",
    "print(pesos0)\n",
    "print(len(pesos0))\n",
    "pesos1 = classificador.layers[1].get_weights()\n",
    "pesos2 = classificador.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 997us/step - loss: 0.4201 - binary_accuracy: 0.8671\n"
     ]
    }
   ],
   "source": [
    "previsoes = classificador.predict(previsores_teste)\n",
    "previsoes = (previsoes > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "\n",
    "resultado = classificador.evaluate(previsores_teste, classe_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
